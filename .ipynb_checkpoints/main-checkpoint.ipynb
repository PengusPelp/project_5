{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maxwiedmann/DSI_project_5__ee_water_levels/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "---\n",
    "### <i>Classifier Modeling</i>\n",
    "----\n",
    "Here we will import water–level depths from Google Earth Engine measured by counting isolated water pixels over time. In conjunction with the image reading we have obtained a csv file from NOAA (National Oceanic and Atmospheric Administration) detailing storm data in Butte County, CA. This data spans from 2013–04–27 to 2020–07–26.\n",
    "\n",
    "Gaps in calendar dates between the two csv files will be filled with a `daterange()` function while missing water levels will be imputed with a seasonal mean in an effort to maintain our record counts. Alleviating missing values (i.e. images that were not recorded in GEE for certain dates) could concisderably affect our model if any gaps in months/seasons were observed.\n",
    "\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## set html cleaning tag for readme\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier,\\\n",
    "AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# GEE Water Pixel Measurement.\n",
    "water = pd.read_csv('./Charts/data/houston_water_levels_data.csv')\n",
    "# NOAA storm dataset.\n",
    "storm_df = pd.read_csv('./storm_data_search_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:time_start</th>\n",
       "      <th>waterArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mar 27, 2013</td>\n",
       "      <td>11.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar 27, 2013</td>\n",
       "      <td>20.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 1, 2013</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 1, 2013</td>\n",
       "      <td>6.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 11, 2013</td>\n",
       "      <td>9.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apr 11, 2013</td>\n",
       "      <td>10.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apr 27, 2013</td>\n",
       "      <td>3.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apr 27, 2013</td>\n",
       "      <td>5.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>May 4, 2013</td>\n",
       "      <td>10.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>May 13, 2013</td>\n",
       "      <td>5.923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  system:time_start  waterArea\n",
       "0      Mar 27, 2013     11.104\n",
       "1      Mar 27, 2013     20.158\n",
       "2       Apr 1, 2013      3.996\n",
       "3       Apr 1, 2013      6.113\n",
       "4      Apr 11, 2013      9.133\n",
       "5      Apr 11, 2013     10.643\n",
       "6      Apr 27, 2013      3.316\n",
       "7      Apr 27, 2013      5.470\n",
       "8       May 4, 2013     10.043\n",
       "9      May 13, 2013      5.923"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n1 = '\\n'\n",
    "print(f\"{n1}WATER TABLE{n1}{n1}{water.info()}{n1}{n1}STORM TABLE{n1}{n1}{storm_df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 529 entries, 0 to 528\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         529 non-null    datetime64[ns]\n",
      " 1   water_level  529 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 8.4 KB\n"
     ]
    }
   ],
   "source": [
    "water['system:time_start'] = pd.to_datetime(water['system:time_start'])\n",
    "water.rename(columns = {'system:time_start': 'date',\n",
    "             'waterArea': 'water_level'}, inplace = True)\n",
    "water.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For some reason we have multiple records for individual dates in our water pixel measurement dataset. This could be due to multiple images being taken in a single day, script bugs, etc.. Due to time constraints in lieu of conducting de–bugging on the script we will instead take the average water level recorded of any duplicative dates.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-08-08    2\n",
       "2016-01-30    2\n",
       "2015-08-14    2\n",
       "2020-07-10    2\n",
       "2017-06-09    2\n",
       "             ..\n",
       "2015-04-08    1\n",
       "2017-08-03    1\n",
       "2016-11-29    1\n",
       "2013-10-27    1\n",
       "2018-09-23    1\n",
       "Name: date, Length: 282, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water['date'].value_counts()\n",
    "#do a date groupby.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#`df.resample()` is similar to `df.groupby()`, but with dates instead of categories.\n",
    "    # this will ALSO fill in any gaps in dates and eliminate need for daterange()\n",
    "water.set_index('date',inplace = True)\n",
    "water.sort_index(inplace = True)\n",
    "water = water.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-27</th>\n",
       "      <td>15.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            water_level\n",
       "date                   \n",
       "2013-03-27       15.631\n",
       "2013-03-28          NaN\n",
       "2013-03-29          NaN\n",
       "2013-03-30          NaN\n",
       "2013-03-31          NaN"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   BEGIN_LOCATION  82 non-null     object \n",
      " 1   BEGIN_DATE      82 non-null     object \n",
      " 2   EVENT_TYPE      82 non-null     object \n",
      " 3   END_LOCATION    82 non-null     object \n",
      " 4   BEGIN_LAT       82 non-null     float64\n",
      " 5   BEGIN_LON       82 non-null     float64\n",
      " 6   END_LAT         82 non-null     float64\n",
      " 7   END_LON         82 non-null     float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 5.2+ KB\n"
     ]
    }
   ],
   "source": [
    "feats = ['BEGIN_LOCATION', 'BEGIN_DATE', 'EVENT_TYPE',\\\n",
    "          'END_LOCATION', 'BEGIN_LAT', \\\n",
    "        'BEGIN_LON', 'END_LAT', 'END_LON']\n",
    "storm_df = storm_df[feats]\n",
    "storm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   loc1      82 non-null     object        \n",
      " 1   date      82 non-null     datetime64[ns]\n",
      " 2   flood     82 non-null     int64         \n",
      " 3   loc2      82 non-null     object        \n",
      " 4   loc1_lat  82 non-null     float64       \n",
      " 5   loc1_lon  82 non-null     float64       \n",
      " 6   loc2_lat  82 non-null     float64       \n",
      " 7   loc2_lon  82 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(2)\n",
      "memory usage: 5.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cols = {\n",
    "    'BEGIN_LOCATION':'loc1',\n",
    "    'BEGIN_DATE':'date',\n",
    "    'EVENT_TYPE':'flood',\n",
    "    'END_LOCATION':'loc2', \n",
    "    'BEGIN_LAT':'loc1_lat', \\\n",
    "    'BEGIN_LON':'loc1_lon',\n",
    "    'END_LAT':'loc2_lat',\n",
    "    'END_LON': 'loc2_lon'\n",
    "}\n",
    "\n",
    "storm_df.rename(columns=cols, inplace=True)\n",
    "storm_df['date'] = pd.to_datetime(storm_df['date'])\n",
    "storm_df['flood'] = 1\n",
    "storm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dataframe to fill in date gaps within data.\n",
    "# df = pd.DataFrame(pd.date_range(min(water['date']), max(water['date'])), columns = ['dates'])\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>loc1</th>\n",
       "      <th>flood</th>\n",
       "      <th>loc2</th>\n",
       "      <th>loc1_lat</th>\n",
       "      <th>loc1_lon</th>\n",
       "      <th>loc2_lat</th>\n",
       "      <th>loc2_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-27</th>\n",
       "      <td>15.631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            water_level loc1  flood loc2  loc1_lat  loc1_lon  loc2_lat  \\\n",
       "date                                                                     \n",
       "2013-03-27       15.631  NaN    NaN  NaN       NaN       NaN       NaN   \n",
       "2013-03-28          NaN  NaN    NaN  NaN       NaN       NaN       NaN   \n",
       "2013-03-29          NaN  NaN    NaN  NaN       NaN       NaN       NaN   \n",
       "2013-03-30          NaN  NaN    NaN  NaN       NaN       NaN       NaN   \n",
       "2013-03-31          NaN  NaN    NaN  NaN       NaN       NaN       NaN   \n",
       "\n",
       "            loc2_lon  \n",
       "date                  \n",
       "2013-03-27       NaN  \n",
       "2013-03-28       NaN  \n",
       "2013-03-29       NaN  \n",
       "2013-03-30       NaN  \n",
       "2013-03-31       NaN  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(water, storm_df, left_on = water.index, right_on= storm_df['date'], right_index=False, how = 'left')\n",
    "df.drop(axis = 1, columns = ['date'], inplace = True)\n",
    "df.rename(columns = {'key_0':'date'},inplace = True)\n",
    "df.set_index('date',inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN with 30 rolling avg\n",
    "df['water_level'].fillna(df[\"water_level\"].rolling(min_periods=1, center=True, window=30).mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['flood'].fillna(value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flood'].replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_level    float64\n",
       "loc1            object\n",
       "flood          float64\n",
       "loc2            object\n",
       "loc1_lat       float64\n",
       "loc1_lon       float64\n",
       "loc2_lat       float64\n",
       "loc2_lon       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Create features to measure water level changes as well as percent changes. These should be strong predictors in a flood classification model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_chg'] = df['water_level'].diff()\n",
    "df['water_chg'].replace(np.nan, 0, inplace=True)\n",
    "df['water_pct_chg'] = df['water_level'].pct_change()\n",
    "df['water_pct_chg'].replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2709 entries, 2013-03-27 to 2020-07-26\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   water_level    2689 non-null   float64\n",
      " 1   loc1           82 non-null     object \n",
      " 2   flood          2709 non-null   float64\n",
      " 3   loc2           82 non-null     object \n",
      " 4   loc1_lat       82 non-null     float64\n",
      " 5   loc1_lon       82 non-null     float64\n",
      " 6   loc2_lat       82 non-null     float64\n",
      " 7   loc2_lon       82 non-null     float64\n",
      " 8   water_chg      2709 non-null   float64\n",
      " 9   water_pct_chg  2709 non-null   float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 232.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>loc1</th>\n",
       "      <th>flood</th>\n",
       "      <th>loc2</th>\n",
       "      <th>loc1_lat</th>\n",
       "      <th>loc1_lon</th>\n",
       "      <th>loc2_lat</th>\n",
       "      <th>loc2_lon</th>\n",
       "      <th>water_chg</th>\n",
       "      <th>water_pct_chg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-04-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            water_level loc1  flood loc2  loc1_lat  loc1_lon  loc2_lat  \\\n",
       "date                                                                     \n",
       "2014-04-21          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-04-22          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-26          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-27          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-28          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-29          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-30          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2014-12-31          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2015-01-01          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2015-01-02          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2015-01-03          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-04          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-05          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-06          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-07          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-08          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-09          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-10          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-11          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "2018-02-12          NaN  NaN    0.0  NaN       NaN       NaN       NaN   \n",
       "\n",
       "            loc2_lon  water_chg  water_pct_chg  \n",
       "date                                            \n",
       "2014-04-21       NaN        0.0            0.0  \n",
       "2014-04-22       NaN        0.0            0.0  \n",
       "2014-12-26       NaN        0.0            0.0  \n",
       "2014-12-27       NaN        0.0            0.0  \n",
       "2014-12-28       NaN        0.0            0.0  \n",
       "2014-12-29       NaN        0.0            0.0  \n",
       "2014-12-30       NaN        0.0            0.0  \n",
       "2014-12-31       NaN        0.0            0.0  \n",
       "2015-01-01       NaN        0.0            0.0  \n",
       "2015-01-02       NaN        0.0            0.0  \n",
       "2015-01-03       NaN        0.0            0.0  \n",
       "2018-02-04       NaN        0.0            0.0  \n",
       "2018-02-05       NaN        0.0            0.0  \n",
       "2018-02-06       NaN        0.0            0.0  \n",
       "2018-02-07       NaN        0.0            0.0  \n",
       "2018-02-08       NaN        0.0            0.0  \n",
       "2018-02-09       NaN        0.0            0.0  \n",
       "2018-02-10       NaN        0.0            0.0  \n",
       "2018-02-11       NaN        0.0            0.0  \n",
       "2018-02-12       NaN        0.0            0.0  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['water_level'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.969731\n",
       "1.0    0.030269\n",
       "Name: flood, dtype: float64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flood'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Baseline model must predict with greater than 3% accurracy if there will be a flood.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['flood', 'water_level', 'water_chg', \"water_pct_chg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2689 entries, 2013-03-27 to 2020-07-26\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   flood          2689 non-null   float64\n",
      " 1   water_level    2689 non-null   float64\n",
      " 2   water_chg      2689 non-null   float64\n",
      " 3   water_pct_chg  2689 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 105.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isfinite(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_chg'] = round(df['water_chg'], 1)\n",
    "df['water_pct_chg'] = round(df['water_pct_chg'], 1)\n",
    "df['water_level'] = round(df['water_level'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-5fe1359694e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Our preliminary model will predict flood occurrence with {round((lr.score(X_train_df, y_train))*100,1)}% accurracy.{n1}Untrained data will predict with {round((lr.score(X_test_df, y_test))*100,1)}% accurracy.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Preliminary model\n",
    "    # model and plot confusion matrix to optimize for type II errors (i.e no flood when true is flood)\n",
    "\n",
    "# It is key that we stratify Y here as there are few instances of our target (floods) actually recorded. \n",
    "# ALSO SHOULD NOTE THAT THERE WILL BE AUTOCORR WITH ENGINEERED FEATURES AND MULTICOLL WITH TIME\n",
    "feats = ['water_level', 'water_chg', \"water_pct_chg\"]\n",
    "\n",
    "X = df[feats]\n",
    "y = df['flood']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "n1 = '\\n'\n",
    "print(f\"Our preliminary model will predict flood occurrence with {round((lr.score(X_train_df, y_train))*100,1)}% accurracy.{n1}Untrained data will predict with {round((lr.score(X_test_df, y_test))*100,1)}% accurracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Ensemble Models\n",
    "knn_pipe = Pipeline([('ss', StandardScaler(with_mean = False)),\n",
    "                    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "vote = VotingClassifier([('ada', AdaBoostClassifier()),\n",
    "                        ('grad_boost', GradientBoostingClassifier()),\n",
    "                         ('XGB', xgb.XGBClassifier()),\n",
    "                        ('knn_pipe', knn_pipe)])\n",
    "\n",
    "# MUST USE DUNDERS TO DENOTE MODELS B/C OF SHARED PARAMS\n",
    "params = {\n",
    "    'ada__n_estimators': [100, 150, 200],\n",
    "    'knn_pipe__knn__n_neighbors' : [1,2,3,4,5,10,20],\n",
    "    'XGB__max_depth' : [10, 20, 30, 40],\n",
    "    'XGB__booster' : ['gbtree', 'gblinear', 'dart']\n",
    "}\n",
    "# with KNN there are two levels to go through i.e 2 dunders\n",
    "gs = GridSearchCV(vote, params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([('ss', StandardScaler(with_mean = False)),\n",
    "                    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "vote = VotingClassifier([('ada', AdaBoostClassifier()),\n",
    "                        ('grad_boost', GradientBoostingClassifier()),\n",
    "                         ('XGB', xgb.XGBClassifier()),\n",
    "                        ('knn_pipe', knn_pipe)])\n",
    "\n",
    "# MUST USE DUNDERS TO DENOTE MODELS B/C OF SHARED PARAMS\n",
    "params = {\n",
    "    'ada__n_estimators': [100, 150, 200],\n",
    "    'knn_pipe__knn__n_neighbors' : [1,2,3,4,5,10,20],\n",
    "    'XGB__max_depth' : [10, 20, 30, 40],\n",
    "    'XGB__booster' : ['gbtree', 'gblinear', 'dart']\n",
    "}\n",
    "# with KNN there are two levels to go through i.e 2 dunders\n",
    "gs = GridSearchCV(vote, params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "#### Model Measurement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "preds = gs.predict(X_test)\n",
    "tn,fp,fn,tp = confusion_matrix(y_test,preds).ravel()\n",
    "plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d');\n",
    "\n",
    "# Calc'ing how often it is accurately predicting flooding\n",
    "tp/(tp+fn)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyIwwy9O9fvhQu3qupNFj4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
